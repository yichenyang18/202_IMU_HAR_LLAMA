{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b53e3b-00c0-4fd0-8e86-8add0d1bf7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d39b7dba-8999-4821-a398-36878d26986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=6, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ad6af4-61b4-4d64-aaaf-02d0ad20c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780fa92c-6b1f-4c0c-929a-6f0fb4b01509",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3cace7a-1048-466c-b027-6485c41c76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\cheng\\Desktop\\202A Project\\UCI HAR Dataset\\UCI HAR Dataset\\train\\y_train.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        y_train.append(int(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39cf573-a7e3-4373-b869-88aa29d88deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = r'C:\\Users\\cheng\\Desktop\\202A Project\\UCI HAR Dataset\\UCI HAR Dataset\\train\\Inertial Signals'\n",
    "\n",
    "train_data = {}\n",
    "train_names = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        file_lines = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                file_lines.append(float(line[:15]))\n",
    "        train_data[filename[:-4]] = file_lines\n",
    "        train_names.append(filename[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ccdac2-e2fc-4fea-bdd6-b1783c3b284b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_acc_x_train</th>\n",
       "      <th>body_acc_y_train</th>\n",
       "      <th>body_acc_z_train</th>\n",
       "      <th>body_gyro_x_train</th>\n",
       "      <th>body_gyro_y_train</th>\n",
       "      <th>body_gyro_z_train</th>\n",
       "      <th>total_acc_x_train</th>\n",
       "      <th>total_acc_y_train</th>\n",
       "      <th>total_acc_z_train</th>\n",
       "      <th>y_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.808515</td>\n",
       "      <td>1.076681</td>\n",
       "      <td>5.556068</td>\n",
       "      <td>3.019122</td>\n",
       "      <td>6.601362</td>\n",
       "      <td>2.285864</td>\n",
       "      <td>1.012817</td>\n",
       "      <td>-1.232167</td>\n",
       "      <td>1.029341</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.093752</td>\n",
       "      <td>-4.687588</td>\n",
       "      <td>-2.685954</td>\n",
       "      <td>1.711106</td>\n",
       "      <td>6.122797</td>\n",
       "      <td>1.226815</td>\n",
       "      <td>1.018851</td>\n",
       "      <td>-1.239760</td>\n",
       "      <td>9.792958</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.531266</td>\n",
       "      <td>4.455942</td>\n",
       "      <td>-5.914581</td>\n",
       "      <td>2.618877</td>\n",
       "      <td>-2.383410</td>\n",
       "      <td>2.158897</td>\n",
       "      <td>1.023127</td>\n",
       "      <td>-1.200157</td>\n",
       "      <td>9.111667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.772352</td>\n",
       "      <td>-1.018541</td>\n",
       "      <td>1.053255</td>\n",
       "      <td>-3.751574</td>\n",
       "      <td>-1.288632</td>\n",
       "      <td>-8.727416</td>\n",
       "      <td>1.017682</td>\n",
       "      <td>-1.334039</td>\n",
       "      <td>9.515180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.747685</td>\n",
       "      <td>-3.856929</td>\n",
       "      <td>-1.333336</td>\n",
       "      <td>-1.942932</td>\n",
       "      <td>-8.612378</td>\n",
       "      <td>-1.574010</td>\n",
       "      <td>1.019952</td>\n",
       "      <td>-1.287306</td>\n",
       "      <td>8.084140</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_acc_x_train  body_acc_y_train  body_acc_z_train  body_gyro_x_train  \\\n",
       "0          1.808515          1.076681          5.556068           3.019122   \n",
       "1          1.093752         -4.687588         -2.685954           1.711106   \n",
       "2          3.531266          4.455942         -5.914581           2.618877   \n",
       "3         -1.772352         -1.018541          1.053255          -3.751574   \n",
       "4          8.747685         -3.856929         -1.333336          -1.942932   \n",
       "\n",
       "   body_gyro_y_train  body_gyro_z_train  total_acc_x_train  total_acc_y_train  \\\n",
       "0           6.601362           2.285864           1.012817          -1.232167   \n",
       "1           6.122797           1.226815           1.018851          -1.239760   \n",
       "2          -2.383410           2.158897           1.023127          -1.200157   \n",
       "3          -1.288632          -8.727416           1.017682          -1.334039   \n",
       "4          -8.612378          -1.574010           1.019952          -1.287306   \n",
       "\n",
       "   total_acc_z_train  y_train  \n",
       "0           1.029341        5  \n",
       "1           9.792958        5  \n",
       "2           9.111667        5  \n",
       "3           9.515180        5  \n",
       "4           8.084140        5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in train_data.items()]))\n",
    "df['y_train'] = y_train\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a607d70-ba8d-4757-a5a7-b1bd43f56866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          text_input\n",
      "0  body_acc_x: 1.808515, body_acc_y: 1.076681, bo...\n",
      "1  body_acc_x: 1.093752, body_acc_y: -4.687588, b...\n",
      "2  body_acc_x: 3.531266, body_acc_y: 4.455942, bo...\n",
      "3  body_acc_x: -1.772352, body_acc_y: -1.018541, ...\n",
      "4  body_acc_x: 8.747685, body_acc_y: -3.856929, b...\n"
     ]
    }
   ],
   "source": [
    "activity_map = {\n",
    "    1: \"Walking\",\n",
    "    2: \"Walking Upstairs\",\n",
    "    3: \"Walking Downstairs\",\n",
    "    4: \"Sitting\",\n",
    "    5: \"Standing\",\n",
    "    6: \"Laying\"\n",
    "}\n",
    "def create_text_format(row):\n",
    "    imu_data = (\n",
    "        f\"body_acc_x: {row['body_acc_x_train']}, body_acc_y: {row['body_acc_y_train']}, body_acc_z: {row['body_acc_z_train']}, \"\n",
    "        f\"body_gyro_x: {row['body_gyro_x_train']}, body_gyro_y: {row['body_gyro_y_train']}, body_gyro_z: {row['body_gyro_z_train']}, \"\n",
    "        f\"total_acc_x: {row['total_acc_x_train']}, total_acc_y: {row['total_acc_y_train']}, total_acc_z: {row['total_acc_z_train']}\"\n",
    "    )\n",
    "    label = activity_map[row['y_train']]  # Map numeric label to activity name\n",
    "    return f\"{imu_data} -> {label}\"\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['text_input'] = df.apply(create_text_format, axis=1)\n",
    "\n",
    "# Output a sample\n",
    "print(df[['text_input']].head())\n",
    "\n",
    "# Now the `df['text_input']` column contains the text-based data that you can feed into the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12418314-8859-4222-9b1a-c929bdc0f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardata = df.drop(['body_acc_x_train','body_acc_y_train','body_acc_z_train','body_gyro_x_train','body_gyro_y_train','body_gyro_z_train','total_acc_x_train','total_acc_y_train','total_acc_z_train'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debe143e-3b32-4922-94ed-37cce355d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardata = hardata.rename(columns={'y_train': 'label'})\n",
    "hardata = hardata.rename(columns={'text_input': 'text'})\n",
    "hardata['label'] = hardata['label'] - 1\n",
    "hardata = hardata[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3753b82f-78ec-42a4-9e38-6f1e02529452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "0     body_acc_x: 1.808515, body_acc_y: 1.076681, bo...      4\n",
      "1     body_acc_x: 1.093752, body_acc_y: -4.687588, b...      4\n",
      "2     body_acc_x: 3.531266, body_acc_y: 4.455942, bo...      4\n",
      "3     body_acc_x: -1.772352, body_acc_y: -1.018541, ...      4\n",
      "4     body_acc_x: 8.747685, body_acc_y: -3.856929, b...      4\n",
      "...                                                 ...    ...\n",
      "7347  body_acc_x: 3.888726, body_acc_y: -4.914403, b...      1\n",
      "7348  body_acc_x: 7.118643, body_acc_y: -3.718694, b...      1\n",
      "7349  body_acc_x: -2.267175, body_acc_y: 5.684462, b...      1\n",
      "7350  body_acc_x: -6.480597, body_acc_y: -5.740777, ...      1\n",
      "7351  body_acc_x: -1.944707, body_acc_y: -9.723743, ...      1\n",
      "\n",
      "[7352 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc5c841-ce2d-4760-b5d8-93346669bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_27456\\1793713350.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  hardata = hardata.groupby('label').apply(lambda x: x.sample(n=25, replace=True) if len(x) > 150 else x)\n"
     ]
    }
   ],
   "source": [
    "hardata = hardata.groupby('label').apply(lambda x: x.sample(n=25, replace=True) if len(x) > 150 else x)\n",
    "label_counts = hardata['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ef8997-bcd4-4263-82d9-fd8214299cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         text  label\n",
      "label                                                               \n",
      "0     6735  body_acc_x: -3.53188, body_acc_y: 8.261802, bo...      0\n",
      "      4314  body_acc_x: 1.170017, body_acc_y: 2.371527, bo...      0\n",
      "      4485  body_acc_x: 1.824135, body_acc_y: -3.71726, bo...      0\n",
      "      1256  body_acc_x: 6.907219, body_acc_y: -2.610314, b...      0\n",
      "      2315  body_acc_x: 8.270954, body_acc_y: -4.70174, bo...      0\n",
      "...                                                       ...    ...\n",
      "5     3523  body_acc_x: -6.963512, body_acc_y: 2.075143, b...      5\n",
      "      5941  body_acc_x: -5.477443, body_acc_y: -1.519692, ...      5\n",
      "      1974  body_acc_x: 3.008573, body_acc_y: -1.280107, b...      5\n",
      "      409   body_acc_x: 1.981402, body_acc_y: 6.886085, bo...      5\n",
      "      1975  body_acc_x: 4.122335, body_acc_y: 4.250997, bo...      5\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "774a8e03-1030-4909-8fbb-e2a9cbe2c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForSequenceClassification,AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0496725-2c32-486a-9bea-f09b61820dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Paste your token here\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7d6eab-1fde-4801-a311-6a928654c689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41463c4b8d4d44bf8393ebee9e7588fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-3B')\n",
    "model = LlamaForSequenceClassification.from_pretrained('meta-llama/Llama-3.2-3B', num_labels = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af2d54cd-ffdd-41cf-ae0b-c97eac5d76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bdab02e-d34e-433e-ae50-f2aa3ba8d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(texts, labels, tokenizer, max_length=512):\n",
    "    tokenized = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    return tokenized, torch.tensor(labels)\n",
    "\n",
    "class HARDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "texts = hardata['text'].tolist()\n",
    "labels = hardata['label'].tolist()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_encodings, train_labels = tokenize_data(train_texts, train_labels, tokenizer)\n",
    "val_encodings, val_labels = tokenize_data(val_texts, val_labels, tokenizer)\n",
    "train_dataset = HARDataset(train_encodings, train_labels)\n",
    "val_dataset = HARDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899adb04-e665-4d02-b7bf-ca56de1d3722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.26.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cheng\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cheng\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c753d3-e66b-4333-aef4-680e71011569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cheng\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheng\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1590: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/3 : < :, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, preds)}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1,\n",
    "    no_cuda=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate()\n",
    "print(\"Llama 3.2 3B Test Accuracy:\", results[\"eval_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1961d6a-3c34-4698-985a-64110b7fc53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_llama3.2_1b_har_class1\\\\tokenizer_config.json',\n",
       " './fine_tuned_llama3.2_1b_har_class1\\\\special_tokens_map.json',\n",
       " './fine_tuned_llama3.2_1b_har_class1\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./fine_tuned_llama3.2_1b_har_class1\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_llama3.2_1b_har_class1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27d47317-e82c-4e47-a13c-98b7777826c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='fine_tuned_llama3.2_1b_har_class1.zip' target='_blank'>fine_tuned_llama3.2_1b_har_class1.zip</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\cheng\\Desktop\\fine_tuned_llama3.2_1b_har_class1.zip"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import make_archive\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Zip the saved model\n",
    "make_archive(\"fine_tuned_llama3.2_1b_har_class1\", 'zip', \"./fine_tuned_llama3.2_1b_har_class1\")\n",
    "\n",
    "# Create a download link for the zipped file\n",
    "FileLink(\"fine_tuned_llama3.2_1b_har_class1.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba129f-0ad1-4537-9c9e-fdec57427617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
