{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b53e3b-00c0-4fd0-8e86-8add0d1bf7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting sentencepiece\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c6/97/d159c32642306ee2b70732077632895438867b3b6df282354bd550cf2a67/sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "     ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "     ---------------------------- -------- 757.8/992.0 kB 24.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- 992.0/992.0 kB 20.9 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ad6af4-61b4-4d64-aaaf-02d0ad20c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780fa92c-6b1f-4c0c-929a-6f0fb4b01509",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3cace7a-1048-466c-b027-6485c41c76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\cheng\\Desktop\\202A Project\\UCI HAR Dataset\\UCI HAR Dataset\\train\\y_train.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        y_train.append(int(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39cf573-a7e3-4373-b869-88aa29d88deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = r'C:\\Users\\cheng\\Desktop\\202A Project\\UCI HAR Dataset\\UCI HAR Dataset\\train\\Inertial Signals'\n",
    "\n",
    "train_data = {}\n",
    "train_names = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        file_lines = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                file_lines.append(float(line[:15]))\n",
    "        train_data[filename[:-4]] = file_lines\n",
    "        train_names.append(filename[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ccdac2-e2fc-4fea-bdd6-b1783c3b284b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_acc_x_train</th>\n",
       "      <th>body_acc_y_train</th>\n",
       "      <th>body_acc_z_train</th>\n",
       "      <th>body_gyro_x_train</th>\n",
       "      <th>body_gyro_y_train</th>\n",
       "      <th>body_gyro_z_train</th>\n",
       "      <th>total_acc_x_train</th>\n",
       "      <th>total_acc_y_train</th>\n",
       "      <th>total_acc_z_train</th>\n",
       "      <th>y_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.808515</td>\n",
       "      <td>1.076681</td>\n",
       "      <td>5.556068</td>\n",
       "      <td>3.019122</td>\n",
       "      <td>6.601362</td>\n",
       "      <td>2.285864</td>\n",
       "      <td>1.012817</td>\n",
       "      <td>-1.232167</td>\n",
       "      <td>1.029341</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.093752</td>\n",
       "      <td>-4.687588</td>\n",
       "      <td>-2.685954</td>\n",
       "      <td>1.711106</td>\n",
       "      <td>6.122797</td>\n",
       "      <td>1.226815</td>\n",
       "      <td>1.018851</td>\n",
       "      <td>-1.239760</td>\n",
       "      <td>9.792958</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.531266</td>\n",
       "      <td>4.455942</td>\n",
       "      <td>-5.914581</td>\n",
       "      <td>2.618877</td>\n",
       "      <td>-2.383410</td>\n",
       "      <td>2.158897</td>\n",
       "      <td>1.023127</td>\n",
       "      <td>-1.200157</td>\n",
       "      <td>9.111667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.772352</td>\n",
       "      <td>-1.018541</td>\n",
       "      <td>1.053255</td>\n",
       "      <td>-3.751574</td>\n",
       "      <td>-1.288632</td>\n",
       "      <td>-8.727416</td>\n",
       "      <td>1.017682</td>\n",
       "      <td>-1.334039</td>\n",
       "      <td>9.515180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.747685</td>\n",
       "      <td>-3.856929</td>\n",
       "      <td>-1.333336</td>\n",
       "      <td>-1.942932</td>\n",
       "      <td>-8.612378</td>\n",
       "      <td>-1.574010</td>\n",
       "      <td>1.019952</td>\n",
       "      <td>-1.287306</td>\n",
       "      <td>8.084140</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_acc_x_train  body_acc_y_train  body_acc_z_train  body_gyro_x_train  \\\n",
       "0          1.808515          1.076681          5.556068           3.019122   \n",
       "1          1.093752         -4.687588         -2.685954           1.711106   \n",
       "2          3.531266          4.455942         -5.914581           2.618877   \n",
       "3         -1.772352         -1.018541          1.053255          -3.751574   \n",
       "4          8.747685         -3.856929         -1.333336          -1.942932   \n",
       "\n",
       "   body_gyro_y_train  body_gyro_z_train  total_acc_x_train  total_acc_y_train  \\\n",
       "0           6.601362           2.285864           1.012817          -1.232167   \n",
       "1           6.122797           1.226815           1.018851          -1.239760   \n",
       "2          -2.383410           2.158897           1.023127          -1.200157   \n",
       "3          -1.288632          -8.727416           1.017682          -1.334039   \n",
       "4          -8.612378          -1.574010           1.019952          -1.287306   \n",
       "\n",
       "   total_acc_z_train  y_train  \n",
       "0           1.029341        5  \n",
       "1           9.792958        5  \n",
       "2           9.111667        5  \n",
       "3           9.515180        5  \n",
       "4           8.084140        5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in train_data.items()]))\n",
    "df['y_train'] = y_train\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a607d70-ba8d-4757-a5a7-b1bd43f56866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          text_input\n",
      "0  body_acc_x: 1.808515, body_acc_y: 1.076681, bo...\n",
      "1  body_acc_x: 1.093752, body_acc_y: -4.687588, b...\n",
      "2  body_acc_x: 3.531266, body_acc_y: 4.455942, bo...\n",
      "3  body_acc_x: -1.772352, body_acc_y: -1.018541, ...\n",
      "4  body_acc_x: 8.747685, body_acc_y: -3.856929, b...\n"
     ]
    }
   ],
   "source": [
    "activity_map = {\n",
    "    1: \"Walking\",\n",
    "    2: \"Walking Upstairs\",\n",
    "    3: \"Walking Downstairs\",\n",
    "    4: \"Sitting\",\n",
    "    5: \"Standing\",\n",
    "    6: \"Laying\"\n",
    "}\n",
    "def create_text_format(row):\n",
    "    imu_data = (\n",
    "        f\"body_acc_x: {row['body_acc_x_train']}, body_acc_y: {row['body_acc_y_train']}, body_acc_z: {row['body_acc_z_train']}, \"\n",
    "        f\"body_gyro_x: {row['body_gyro_x_train']}, body_gyro_y: {row['body_gyro_y_train']}, body_gyro_z: {row['body_gyro_z_train']}, \"\n",
    "        f\"total_acc_x: {row['total_acc_x_train']}, total_acc_y: {row['total_acc_y_train']}, total_acc_z: {row['total_acc_z_train']}\"\n",
    "    )\n",
    "    return f\"{imu_data}\"\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['text_input'] = df.apply(create_text_format, axis=1)\n",
    "\n",
    "# Output a sample\n",
    "print(df[['text_input']].head())\n",
    "\n",
    "# Now the `df['text_input']` column contains the text-based data that you can feed into the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12418314-8859-4222-9b1a-c929bdc0f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardata = df.drop(['body_acc_x_train','body_acc_y_train','body_acc_z_train','body_gyro_x_train','body_gyro_y_train','body_gyro_z_train','total_acc_x_train','total_acc_y_train','total_acc_z_train'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debe143e-3b32-4922-94ed-37cce355d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardata = hardata.rename(columns={'y_train': 'label'})\n",
    "hardata = hardata.rename(columns={'text_input': 'text'})\n",
    "hardata['label'] = hardata['label'] - 1\n",
    "hardata = hardata[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3753b82f-78ec-42a4-9e38-6f1e02529452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "0     body_acc_x: 1.808515, body_acc_y: 1.076681, bo...      4\n",
      "1     body_acc_x: 1.093752, body_acc_y: -4.687588, b...      4\n",
      "2     body_acc_x: 3.531266, body_acc_y: 4.455942, bo...      4\n",
      "3     body_acc_x: -1.772352, body_acc_y: -1.018541, ...      4\n",
      "4     body_acc_x: 8.747685, body_acc_y: -3.856929, b...      4\n",
      "...                                                 ...    ...\n",
      "7347  body_acc_x: 3.888726, body_acc_y: -4.914403, b...      1\n",
      "7348  body_acc_x: 7.118643, body_acc_y: -3.718694, b...      1\n",
      "7349  body_acc_x: -2.267175, body_acc_y: 5.684462, b...      1\n",
      "7350  body_acc_x: -6.480597, body_acc_y: -5.740777, ...      1\n",
      "7351  body_acc_x: -1.944707, body_acc_y: -9.723743, ...      1\n",
      "\n",
      "[7352 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc5c841-ce2d-4760-b5d8-93346669bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_18532\\1963602221.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  hardata = hardata.groupby('label').apply(lambda x: x.sample(300, replace=True) if len(x) > 150 else x)\n"
     ]
    }
   ],
   "source": [
    "hardata = hardata.groupby('label').apply(lambda x: x.sample(300, replace=True) if len(x) > 150 else x)\n",
    "label_counts = hardata['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ef8997-bcd4-4263-82d9-fd8214299cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         text  label\n",
      "label                                                               \n",
      "0     115   body_acc_x: 4.249666, body_acc_y: -3.651249, b...      0\n",
      "      790   body_acc_x: -4.18084, body_acc_y: 1.292447, bo...      0\n",
      "      4323  body_acc_x: 4.120848, body_acc_y: -3.094632, b...      0\n",
      "      4109  body_acc_x: 4.014474, body_acc_y: 1.757964, bo...      0\n",
      "      4817  body_acc_x: 2.226186, body_acc_y: 3.328627, bo...      0\n",
      "...                                                       ...    ...\n",
      "5     5367  body_acc_x: -1.418903, body_acc_y: 1.009241, b...      5\n",
      "      2628  body_acc_x: 6.569172, body_acc_y: -4.752737, b...      5\n",
      "      2949  body_acc_x: 1.724653, body_acc_y: -4.389805, b...      5\n",
      "      213   body_acc_x: 4.577838, body_acc_y: 1.225482, bo...      5\n",
      "      3337  body_acc_x: 9.082774, body_acc_y: -1.040808, b...      5\n",
      "\n",
      "[1800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "774a8e03-1030-4909-8fbb-e2a9cbe2c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForSequenceClassification,AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0496725-2c32-486a-9bea-f09b61820dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Paste your token here\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7d6eab-1fde-4801-a311-6a928654c689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-1B')\n",
    "model = LlamaForSequenceClassification.from_pretrained('meta-llama/Llama-3.2-1B', num_labels = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af2d54cd-ffdd-41cf-ae0b-c97eac5d76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bdab02e-d34e-433e-ae50-f2aa3ba8d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(texts, labels, tokenizer, max_length=512):\n",
    "    tokenized = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    return tokenized, torch.tensor(labels)\n",
    "\n",
    "class HARDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "texts = hardata['text'].tolist()\n",
    "labels = hardata['label'].tolist()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_encodings, train_labels = tokenize_data(train_texts, train_labels, tokenizer)\n",
    "val_encodings, val_labels = tokenize_data(val_texts, val_labels, tokenizer)\n",
    "#train_dataset = HARDataset(train_encodings, train_labels)\n",
    "#val_dataset = HARDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9adc143-6173-44cc-a8e7-0ad3539214ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "# Move encodings and labels to GPU\n",
    "train_encodings = {key: val.to(device) for key, val in train_encodings.items()}\n",
    "train_labels = train_labels.to(device)\n",
    "val_encodings = {key: val.to(device) for key, val in val_encodings.items()}\n",
    "val_labels = val_labels.to(device)\n",
    "\n",
    "train_dataset = HARDataset(train_encodings, train_labels)\n",
    "val_dataset = HARDataset(val_encodings, val_labels)\n",
    "\n",
    "# DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b7437af-d5bc-4161-9ef7-f83437217887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 2.4645771622657775\n",
      "Epoch 2/3, Loss: 1.9059289044804044\n",
      "Epoch 3/3, Loss: 1.84606308804618\n",
      "Validation Accuracy: 0.3528\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # Move batch data to GPU\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# Validation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Validation Accuracy: {correct / total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1961d6a-3c34-4698-985a-64110b7fc53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_llama3.2_1b_har_gpu\\\\tokenizer_config.json',\n",
       " './fine_tuned_llama3.2_1b_har_gpu\\\\special_tokens_map.json',\n",
       " './fine_tuned_llama3.2_1b_har_gpu\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./fine_tuned_llama3.2_1b_har_gpu\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_llama3.2_1b_har_gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27d47317-e82c-4e47-a13c-98b7777826c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='fine_tuned_llama3.2_1b_har_gpu.zip' target='_blank'>fine_tuned_llama3.2_1b_har_gpu.zip</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\cheng\\Desktop\\fine_tuned_llama3.2_1b_har_gpu.zip"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import make_archive\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Zip the saved model\n",
    "make_archive(\"fine_tuned_llama3.2_1b_har_gpu\", 'zip', \"./fine_tuned_llama3.2_1b_har_gpu\")\n",
    "\n",
    "# Create a download link for the zipped file\n",
    "FileLink(\"fine_tuned_llama3.2_1b_har_gpu.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba129f-0ad1-4537-9c9e-fdec57427617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
